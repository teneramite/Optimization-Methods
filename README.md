# Методы оптимизации - Практические задания

## Автор
**ФИО:** Кисель Софья   
**Поток:** 1.1  
**Дата:** Декабрь 2025

## Описание проекта

Данный репозиторий содержит реализацию 4 заданий по курсу "Методы оптимизации":

1. **Линейное программирование** - Решение задач симплекс-методом
2. **Глобальная оптимизация** - Метод ломаных Пиявского
3. **Условная оптимизация** - Метод множителей Лагранжа
4. **Динамическое программирование** - Управление инвестиционным портфелем

## Структура проекта

```
SONIC/
├── task1_linear_programming/       # Задание 1: Симплекс-метод
│   ├── simplex_solver.py          # Основной решатель
│   ├── input_variant17.json       # Входные данные (вариант 17)
│   ├── demo.py                    # Демонстрация
│   └── README.md                  # Документация
│
├── task2_global_optimization/      # Задание 2: Глобальная оптимизация
│   ├── global_optimizer.py        # Метод Пиявского
│   ├── demo.py                    # Демонстрация на тестовых функциях
│   └── README.md                  # Документация
│
├── task3_lagrange/                 # Задание 3: Метод Лагранжа
│   ├── lagrange_solver.py         # Решатель (вариант 7)
│   └── README.md                  # Документация
│
├── task4_dynamic_programming/      # Задание 4: Динамическое программирование
│   ├── portfolio_optimizer.py     # Оптимизация портфеля
│   └── README.md                  # Документация
│
├── SONIC_DOCA.docx                # Исходная документация
├── SONIC_DOCA_TEXT.txt            # Текстовая версия документации
├── task_1_variant_17.txt          # Условие варианта 17
└── README.md                      # Этот файл
```

## Задания

### Задание 1: Линейное программирование (Симплекс-метод)

**Описание:** Реализация полного цикла решения задач линейного программирования двухфазным симплекс-методом.

**Вариант 17:**
```
Максимизировать: Z = x₁ + 3x₂ + 2x₃ + x₄

При ограничениях:
  x₁ + x₂ + 2x₄ ≤ 8
  x₂ + x₃ + x₄ = 6
  2x₁ + x₃ ≥ 2
  x₁, x₂, x₃, x₄ ≥ 0
```

**Запуск:**
```bash
cd task1_linear_programming
python demo.py
```

**Технологии:** Python, NumPy

---

### Задание 2: Глобальная оптимизация

**Описание:** Поиск глобального минимума одномерной липшицевой функции методом ломаных Пиявского.

**Тестовые функции:**
- Функция Растригина
- Функция Экли
- Пользовательские функции с множественными локальными минимумами

**Запуск:**
```bash
cd task2_global_optimization
python demo.py
```

**Технологии:** Python, NumPy, Matplotlib

---

### Задание 3: Метод множителей Лагранжа

**Описание:** Решение задач условной оптимизации методом множителей Лагранжа с проверкой достаточных условий экстремума.

**Вариант 7:**
```
Минимизировать: f(x,y) = (x-2)² + (y+3)²

При ограничениях:
  g₁(x,y) = 3x + 2y - 4 = 0
  g₂(x,y) = x - y - 1 = 0
```

**Запуск:**
```bash
cd task3_lagrange
python lagrange_solver.py
```

**Технологии:** Python, SymPy, NumPy, Matplotlib

---

### Задание 4: Динамическое программирование

**Описание:** Оптимальное управление инвестиционным портфелем на 3 этапа с вероятностными сценариями.

**Параметры:**
- Начальное состояние: ЦБ1=100, ЦБ2=800, Депозиты=400, Свободные=600 д.е.
- Управление: покупка/продажа долями по 25%
- Критерий: математическое ожидание (критерий Байеса)

**Запуск:**
```bash
cd task4_dynamic_programming
python portfolio_optimizer.py
```

**Технологии:** Python, NumPy, Matplotlib

## Установка зависимостей

```bash
# Для всех заданий
pip install numpy matplotlib

# Дополнительно для задания 3
pip install sympy
```

## Быстрый старт

```bash
# Клонирование репозитория
cd /home/lord/WORK/SONIC

# Установка зависимостей
pip install numpy matplotlib sympy

# Запуск всех демонстраций
python task1_linear_programming/demo.py
python task2_global_optimization/demo.py
python task3_lagrange/lagrange_solver.py
python task4_dynamic_programming/portfolio_optimizer.py
```

## Результаты

### Задание 1
- ✅ Реализован двухфазный симплекс-метод
- ✅ Поддержка всех типов ограничений (≤, =, ≥)
- ✅ Обработка граничных случаев (неограниченность, отсутствие решений)
- ✅ Решен вариант 17

### Задание 2
- ✅ Реализован метод Пиявского
- ✅ Адаптивная оценка константы Липшица
- ✅ Визуализация процесса оптимизации
- ✅ Тестирование на функциях Растригина и Экли

### Задание 3
- ✅ Символьное решение через SymPy
- ✅ Проверка достаточных условий (критерий Сильвестра)
- ✅ Визуализация линий уровня и ограничений
- ✅ Решен вариант 7

### Задание 4
- ✅ Реализовано уравнение Беллмана
- ✅ Учет вероятностей сценариев (критерий Байеса)
- ✅ Учет комиссий и ограничений
- ✅ Визуализация динамики портфеля

## Ключевые концепции

1. **Симплекс-метод:** Эффективный алгоритм решения ЗЛП через перебор угловых точек допустимой области.

2. **Метод Пиявского:** Глобальная оптимизация через построение нижней огибающей с использованием константы Липшица.

3. **Множители Лагранжа:** Преобразование задачи условной оптимизации в задачу решения системы уравнений.

4. **Принцип оптимальности Беллмана:** Разбиение многоэтапной задачи на подзадачи с рекуррентным соотношением.

## Рефлективный вывод

### Что было полезного

1. **Глубокое понимание алгоритмов:** Реализация с нуля позволила понять внутреннее устройство каждого метода.

2. **Практические навыки:** Получен опыт работы с NumPy, SymPy, визуализацией через Matplotlib.

3. **Обработка граничных случаев:** Научился учитывать численную нестабильность, вырожденные случаи, ошибки округления.

4. **Структурирование кода:** Разработка модульной архитектуры с четким разделением ответственности.

### Трудности и их преодоление

1. **Численная стабильность в симплекс-методе:** Использование псевдообратных матриц вместо обычного обращения.

2. **Параметр надёжности в методе Пиявского:** Экспериментальный подбор оптимального значения r = 2-3.

3. **Символьные вычисления в SymPy:** Изучение API для работы с системами уравнений и матрицами.

4. **Комбинаторная сложность в ДП:** Упрощение пространства состояний для практической реализуемости.

### Выводы

Выполнение данного проекта дало комплексное понимание различных подходов к оптимизации:
- **Линейная оптимизация** - для задач с линейными зависимостями
- **Глобальная оптимизация** - для сложных негладких функций
- **Условная оптимизация** - для задач с ограничениями-равенствами
- **Стохастическая оптимизация** - для задач с неопределенностью

Каждый метод имеет свою область применения, и выбор правильного подхода критичен для успешного решения практических задач оптимизации.

## Лицензия

Образовательный проект. Использование свободное с указанием авторства.

## Контакты

[Укажите ваши контакты]

---

**Примечание:** Для корректной работы всех программ требуется Python 3.7+ и установленные зависимости (numpy, matplotlib, sympy).
