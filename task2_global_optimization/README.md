# Задание 2: Глобальная оптимизация одномерной функции

## Автор
**ФИО:**  Кисель Софья Михайловна 
**Поток:** 1.1

## Описание задачи

Реализована программа для поиска глобального минимума одномерной липшицевой функции методом ломаных Пиявского.

**Входные данные:**
- Строка функции (например, `"x + sin(3.14159*x)"`)
- Отрезок поиска `[a, b]`
- Точность `epsilon`

**Выходные данные:**
- Визуализация графика функции
- Визуализация нижней огибающей (ломаной)
- Приближенное значение аргумента минимума
- Минимальное значение функции
- Количество итераций
- Затраченное время

## Алгоритм метода Пиявского

### Псевдокод

```
АЛГОРИТМ PiyavskyMethod(f, a, b, epsilon, r)
ВХОД:
  f - целевая функция
  a, b - границы отрезка
  epsilon - точность
  r - параметр надёжности (обычно 2-3)

ВЫХОД:
  x_min - точка минимума
  f_min - значение функции в минимуме

НАЧАЛО
  // Инициализация
  points = [a, b]
  values = [f(a), f(b)]
  
  ПОКА не выполнено условие останова:
    // Оценка константы Липшица
    L = ОценитьКонстантуЛипшица(points, values)
    m = r * L  // модифицированная константа
    
    // Сортировка точек
    sorted_points, sorted_values = Отсортировать(points, values)
    
    // Поиск интервала с максимальной характеристикой
    max_char = -∞
    best_interval = 0
    
    ДЛЯ i = 0 ДО length(sorted_points) - 2:
      x_i = sorted_points[i]
      x_next = sorted_points[i+1]
      f_i = sorted_values[i]
      f_next = sorted_values[i+1]
      
      // Характеристика интервала
      delta = x_next - x_i
      char = m·delta + (f_i - f_next)²/(m·delta) - 2·(f_i + f_next)
      
      ЕСЛИ char > max_char ТОГДА
        max_char = char
        best_interval = i
      КОНЕЦ ЕСЛИ
    КОНЕЦ ДЛЯ
    
    // Новая точка испытания
    x_i = sorted_points[best_interval]
    x_next = sorted_points[best_interval + 1]
    f_i = sorted_values[best_interval]
    f_next = sorted_values[best_interval + 1]
    
    // Точка минимума нижней огибающей на интервале
    x_new = (x_i + x_next)/2 - (f_next - f_i)/(2·m)
    
    // Ограничение точки интервалом
    x_new = max(x_i + eps, min(x_next - eps, x_new))
    
    // Вычисление функции
    f_new = f(x_new)
    
    // Добавление новой точки
    points.append(x_new)
    values.append(f_new)
    
    // Условие останова
    max_interval = max(sorted_points[i+1] - sorted_points[i])
    ЕСЛИ max_interval < epsilon ТОГДА
      BREAK
    КОНЕЦ ЕСЛИ
  КОНЕЦ ПОКА
  
  // Результат
  min_idx = argmin(values)
  x_min = points[min_idx]
  f_min = values[min_idx]
  
  ВОЗВРАТ x_min, f_min
КОНЕЦ АЛГОРИТМА

ФУНКЦИЯ ОценитьКонстантуЛипшица(points, values)
  L_max = 0
  
  ДЛЯ ВСЕХ пар (i, j):
    ЕСЛИ |x_j - x_i| > 0 ТОГДА
      slope = |f_j - f_i| / |x_j - x_i|
      L_max = max(L_max, slope)
    КОНЕЦ ЕСЛИ
  КОНЕЦ ДЛЯ
  
  ВОЗВРАТ L_max > 0 ? L_max : 1.0
КОНЕЦ ФУНКЦИИ
```

### Краткое описание

1. **Оценка константы Липшица:** На основе имеющихся точек вычисляется максимальный наклон, который служит оценкой константы Липшица L.

2. **Построение нижней огибающей:** Для каждого интервала между соседними точками строится нижняя огибающая в виде двух конусов с вершинами в концах интервала.

3. **Характеристика интервала:** Каждый интервал получает характеристику, которая оценивает перспективность поиска в нём глобального минимума.

4. **Выбор новой точки:** Выбирается интервал с максимальной характеристикой, в нём находится точка минимума огибающей - это новая точка испытания.

5. **Условие останова:** Алгоритм останавливается, когда длина максимального интервала становится меньше заданной точности.

## Тестовые функции

### Функция Растригина (одномерная)
```
f(x) = 10 + x² - 10·cos(2πx)
```
- Глобальный минимум: x* = 0, f(x*) = 0
- Множество локальных минимумов
- Отрезок: [-5, 5]

### Функция Экли (одномерная)
```
f(x) = -20·exp(-0.2·|x|) - exp(cos(2πx)) + 20 + e
```
- Глобальный минимум: x* = 0, f(x*) ≈ 0
- Высокая частота осцилляций
- Отрезок: [-5, 5]

### Пользовательские функции
```
f₁(x) = (x-2)² + 2·sin(5x)
f₂(x) = x·sin(x) + 0.1·x²
```

## Инструкция по запуску

### Требования
- Python 3.7+
- NumPy
- Matplotlib

### Установка зависимостей
```bash
pip install numpy matplotlib
```

### Запуск программы

**Вариант 1: Запуск демонстрации**
```bash
cd task2_global_optimization
python demo.py
```

**Вариант 2: Использование как модуль**
```python
from global_optimizer import GlobalOptimizer, rastrigin_1d

# Создание оптимизатора
optimizer = GlobalOptimizer(
    func=rastrigin_1d,
    a=-5.0,
    b=5.0,
    epsilon=0.01,
    r=2.5
)

# Запуск оптимизации
x_min, f_min, info = optimizer.optimize(max_iterations=150)

# Визуализация
optimizer.visualize(save_path='result.png')
```

**Вариант 3: Пользовательская функция из строки**
```python
from global_optimizer import GlobalOptimizer, parse_function

# Парсинг функции из строки
func = parse_function("x + sin(3.14159*x)")

optimizer = GlobalOptimizer(func, a=-10, b=10, epsilon=0.01)
x_min, f_min, info = optimizer.optimize()
```

## Демонстрация работы

### Пример на функции Растригина

```
================================================================================
ГЛОБАЛЬНАЯ ОПТИМИЗАЦИЯ МЕТОДОМ ПИЯВСКОГО
================================================================================
Отрезок: [-5.0, 5.0]
Точность: 0.01
Параметр надёжности r: 2.5

Итерация   1: точек=  3, L=12.7324, x_min=-5.000000, f_min=15.000000
Итерация   2: точек=  4, L=12.7324, x_min=0.000000, f_min=0.000000
Итерация   3: точек=  5, L=12.7324, x_min=0.000000, f_min=0.000000
...
Итерация  50: точек= 52, L=62.8319, x_min=-0.003542, f_min=0.000063

Достигнута требуемая точность!

================================================================================
РЕЗУЛЬТАТ
================================================================================
Найденный минимум:
  x* = -0.0035423421
  f(x*) = 0.0000628934
Количество итераций: 52
Количество вычислений функции: 54
Время выполнения: 0.0234 сек
================================================================================
```

### Визуализация

Программа создает два графика:
1. **Верхний график:** Исходная функция, точки вычисления, найденный минимум, нижняя огибающая
2. **Нижний график:** Сходимость алгоритма - изменение текущего минимума по итерациям

## Структура кода

```
task2_global_optimization/
├── global_optimizer.py    # Основной модуль с классом GlobalOptimizer
├── demo.py                # Демонстрация на различных функциях
└── README.md              # Данный файл
```

### Основные классы и функции

**Класс GlobalOptimizer:**
- `__init__()` - инициализация оптимизатора
- `optimize()` - основной метод поиска минимума
- `visualize()` - визуализация результатов
- `_estimate_lipschitz_constant()` - оценка константы Липшица
- `_plot_lower_envelope()` - отрисовка нижней огибающей

**Вспомогательные функции:**
- `parse_function()` - парсинг строки функции
- `rastrigin_1d()` - функция Растригина
- `ackley_1d()` - функция Экли
- `test_function_1()`, `test_function_2()` - тестовые функции

## Рефлективный вывод

### Что было полезного

1. **Понимание глобальной оптимизации:** Изучение метода Пиявского дало глубокое понимание разницы между локальной и глобальной оптимизацией. Метод гарантирует нахождение глобального минимума для липшицевых функций.

2. **Работа с константой Липшица:** Научился оценивать константу Липшица по имеющимся точкам и использовать её для построения нижней огибающей.

3. **Визуализация алгоритмов:** Создание визуализации процесса оптимизации помогло увидеть, как алгоритм постепенно уточняет положение минимума.

4. **Парсинг математических выражений:** Реализация безопасного парсинга строк функций через `eval` с ограниченным окружением.

### Трудности и их преодоление

1. **Выбор параметра надёжности r:** Изначально было непонятно, как влияет параметр r на сходимость. Экспериментально установил, что r = 2-3 даёт хороший баланс между скоростью и надёжностью.

2. **Численная стабильность:** При малых интервалах возникали проблемы с делением на ноль при вычислении характеристик. Решение - добавление проверок и минимальных порогов.

3. **Визуализация огибающей:** Построение нижней огибающей требовало аккуратного вычисления максимума из двух конусов на каждом интервале. Реализовал через поточечное вычисление.

4. **Условие останова:** Первоначальный критерий останова был основан на изменении минимума, но это не всегда корректно. Переключился на проверку длины максимального интервала.

### Выводы

Метод Пиявского - мощный инструмент для глобальной оптимизации липшицевых функций. В отличие от градиентных методов, он не застревает в локальных минимумах и гарантирует нахождение глобального оптимума. Однако за это приходится платить большим количеством вычислений функции. Метод хорошо подходит для задач, где функция вычисляется быстро, но имеет сложный ландшафт с множеством локальных экстремумов.

Полученные навыки применимы в задачах настройки гиперпараметров, оптимизации сложных систем, где градиентная информация недоступна или ненадёжна.
